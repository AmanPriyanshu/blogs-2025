[{"content":"Analysis Code: GitHub Gist\nIntroduction In biology, DNA provides the blueprint for how organisms develop and reproduce. In the realm of synthetic reasoning data, we observe a similar phenomenon: specific linguistic patterns that function as \u0026ldquo;reasoning memotypes\u0026rdquo;‚Äîself-replicating units of thought structure that propagate through synthetic data generation.\nAnalysis of Nvidia\u0026rsquo;s Nemotron post-training dataset^[1], which contains over 30 million synthetic examples generated using DeepSeek R1^[2] and other reasoning models, reveals systematic linguistic patterns that appear with extraordinary frequency. These patterns function like genetic code for reasoning behavior, encoding not just what models think, but how they structure and express thought itself.\nCould these represent a form of memetic inheritance that fundamentally shapes how reasoning models learn to think? And if so, could this explain why models fine-tuned or distilled from systems like DeepSeek R1 often exhibit patterns of self-doubt and constant questioning, having inherited these interrogative memotypes as core components of their reasoning DNA?\nThe Discovery: Reasoning DNA in Action Through 4-gram frequency analysis of the Nemotron dataset, we identified linguistic patterns that appear in over 40% of synthetic reasoning samples. These frequencies are so high they suggest systematic replication rather than natural variation.\nThe Core Memotype Sequences These \u0026ldquo;reasoning genes\u0026rdquo; cluster into distinct functional categories:\nProblem Recognition Memotypes:\n\u0026#34;but the problem says\u0026#34; (242,856 occurrences) \u0026#34;according to the problem\u0026#34; (238,464 occurrences) \u0026#34;so the problem is\u0026#34; (230,779 occurrences) Cognitive Initiation Memotypes:\n\u0026#34;okay i need to\u0026#34; (309,055 occurrences) \u0026#34;let s think about\u0026#34; (348,926 occurrences) \u0026#34;okay let s see\u0026#34; (235,759 occurrences) Procedural Reasoning Memotypes:\n\u0026#34;so the steps are\u0026#34; (312,905 occurrences) \u0026#34;for example if the\u0026#34; (333,229 occurrences) \u0026#34;we need to find\u0026#34; (227,076 occurrences) Like genetic sequences that code for specific proteins, these linguistic patterns code for specific reasoning behaviors: problem identification, cognitive engagement, and systematic processing.\nThe Replication Mechanism: From R1-Zero to Synthetic DNA The DeepSeek R1 paper reveals how these reasoning memotypes emerged and spread. The story begins with R1-Zero, a model trained purely through reinforcement learning that exhibited \u0026ldquo;poor readability and language mixing.\u0026rdquo; While this raw model demonstrated genuine reasoning capabilities, it was deemed unsuitable for production use.\nThe Evolutionary Bottleneck DeepSeek\u0026rsquo;s solution created what we might call an \u0026ldquo;evolutionary bottleneck\u0026rdquo; in reasoning expression:\nSelection Pressure: The team collected \u0026ldquo;about 600k reasoning related training samples\u0026rdquo; through rejection sampling, explicitly filtering out responses with \u0026ldquo;mixed languages, long paragraphs, and code blocks.\u0026rdquo;\nStandardization: They introduced format rewards to enforce specific structural patterns, requiring reasoning to be enclosed in \u0026lt;think\u0026gt; tags with standardized discourse markers.\nAmplification: This curated, template-heavy data was used to train the production R1 model, which then generated synthetic data for Nemotron.\nLike a genetic bottleneck that reduces diversity in a population, this process concentrated reasoning expression into a narrow set of linguistic patterns.\nMemetic Inheritance and Propagation These reasoning memotypes exhibit classic characteristics of self-replicating information:\nFidelity: The patterns reproduce with remarkable consistency across hundreds of thousands of samples, maintaining their structure like stable genetic sequences.\nFecundity: High-frequency memotypes dominate the dataset, out-competing more diverse expressions, similar to how successful genes become prevalent in a population.\nLongevity: Once established in DeepSeek R1, these patterns persist and replicate through synthetic data generation, creating a lasting \u0026ldquo;genetic lineage\u0026rdquo; of reasoning behavior.\nThe Synthetic Data Ecosystem What makes this phenomenon particularly concerning is how these memotypes create a self-reinforcing ecosystem:\nInitial Encoding: DeepSeek\u0026rsquo;s transition from R1-Zero to R1 encodes specific reasoning patterns as \u0026ldquo;successful\u0026rdquo; templates Synthetic Amplification: R1 generates synthetic data for Nemotron, replicating these patterns millions of times Training Inheritance: Models trained on Nemotron inherit these reasoning memotypes as fundamental components of their \u0026ldquo;cognitive DNA\u0026rdquo; Generational Transmission: These models may then generate their own synthetic data, further propagating the memotypes This creates what evolutionary biologists would recognize as a \u0026ldquo;selective sweep\u0026rdquo;: a situation where a particular trait becomes dominant across an entire population.\nImplications: Genetic Diversity vs. Optimization Just as genetic diversity is crucial for biological fitness, reasoning diversity appears essential for cognitive robustness. The concentration of specific memotypes raises several concerns:\nCognitive Inbreeding: Like biological inbreeding, excessive reliance on narrow reasoning patterns may reduce adaptive capacity and problem-solving flexibility.\nMemetic Drift: Over successive generations of synthetic data, these patterns may accumulate mutations or degradations, potentially leading to reasoning \u0026ldquo;genetic disorders.\u0026rdquo;\nInnovation Constraints: Highly standardized reasoning memotypes may limit models\u0026rsquo; ability to develop novel problem-solving approaches, analogous to how genetic uniformity reduces evolutionary potential.\nBeyond Templates: Understanding Reasoning Heredity These findings suggest we need to think about synthetic data generation in evolutionary terms. Current approaches may be inadvertently creating \u0026ldquo;monocultures\u0026rdquo; of reasoning behavior: systems that excel at reproducing learned patterns but struggle with genuine cognitive diversity.\nThe biological metaphor reveals why this matters: just as ecosystems thrive on genetic diversity, reasoning capabilities may require linguistic and structural diversity to remain robust and adaptable. When we optimize for \u0026ldquo;readability\u0026rdquo; and \u0026ldquo;human-friendliness,\u0026rdquo; we may be selecting against the very cognitive mutations that enable breakthrough thinking.\nFuture Directions: Cultivating Cognitive Biodiversity Understanding reasoning memotypes opens new research directions:\nMemotype Mapping: Systematically cataloging the reasoning \u0026ldquo;genetic code\u0026rdquo; across different model families and training approaches.\nDiversity Metrics: Developing measures of reasoning biodiversity to evaluate synthetic dataset health, perhaps explaining why models distilled from DeepSeek R1 often exhibit excessive self-doubt and questioning patterns.\nControlled Evolution: Designing training processes that maintain beneficial memotypes while preserving cognitive diversity.\nCross-Breeding Approaches: Combining reasoning patterns from diverse model lineages to prevent cognitive inbreeding.\nShould we be examining trace pattern diversity more carefully when evaluating reasoning model quality? The prevalence of interrogative memotypes in DeepSeek-derived systems suggests that what we consider \u0026ldquo;good reasoning\u0026rdquo; may actually be inherited linguistic artifacts rather than genuine cognitive capabilities.\nConclusion The observation of reasoning memotypes in synthetic data suggests a potential parallel between biological and artificial intelligence evolution. Just as DNA encodes and transmits biological traits, these linguistic patterns may encode and transmit reasoning behaviors across generations of AI systems.\nThe concentration of specific memotypes in Nvidia\u0026rsquo;s Nemotron dataset (generated primarily by DeepSeek R1) represents more than mere template artifacts. These patterns function as the \u0026ldquo;genetic code\u0026rdquo; of synthetic reasoning, determining not just what models think but how they structure thought itself.\nAs we continue scaling AI development through synthetic data, understanding and managing this memetic inheritance becomes crucial. The goal should not be eliminating these patterns entirely, but ensuring sufficient diversity to maintain the cognitive \u0026ldquo;gene pool\u0026rdquo; necessary for continued reasoning evolution.\nThe future of reasoning AI may depend not just on training better models, but on cultivating richer ecosystems of thought: preserving the cognitive biodiversity necessary for artificial minds to continue growing, adapting, and discovering new ways to understand the world.\nReferences:\n[1] Nvidia Llama Nemotron Post-Training Dataset: https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset\n[2] DeepSeek R1 Model: https://huggingface.co/deepseek-ai/DeepSeek-R1\n[3] DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning: https://arxiv.org/abs/2501.12948\nThis analysis was conducted on publicly available data. For questions about methodology or to contribute to ongoing research into reasoning memotypes, please reach out at amanpriyanshu.github.io.\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2025/deepseek-reasoning-memotypes/","summary":"\u003cp\u003e\u003cstrong\u003eAnalysis Code:\u003c/strong\u003e \u003ca href=\"https://gist.github.com/AmanPriyanshu/431df2cefe60386b0fc9cb66802b70d4\"\u003eGitHub Gist\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn biology, DNA provides the blueprint for how organisms develop and reproduce. In the realm of synthetic reasoning data, we observe a similar phenomenon: specific linguistic patterns that function as \u0026ldquo;reasoning memotypes\u0026rdquo;‚Äîself-replicating units of thought structure that propagate through synthetic data generation.\u003c/p\u003e\n\u003cp\u003eAnalysis of Nvidia\u0026rsquo;s Nemotron post-training dataset^[1], which contains over 30 million synthetic examples generated using DeepSeek R1^[2] and other reasoning models, reveals systematic linguistic patterns that appear with extraordinary frequency. These patterns function like genetic code for reasoning behavior, encoding not just what models think, but how they structure and express thought itself.\u003c/p\u003e","title":"DeepSeek's Reasoning Memotypes: Could Linguistic Patterns Be Replicating Through Synthetic Data?"},{"content":"Quick Links: GitHub Repository | Dataset Sample\nIntroduction Spatial reasoning remains a significant challenge for language models, particularly in tasks requiring 2D navigation and visual-spatial understanding. Current approaches typically rely on either training large vision-language models (VLMs) on visual data or using language models to generate training examples through expensive API calls.\nThis post explores what might be considered an unconventional (and possibly naive) approach: deterministic generation of spatial reasoning data without requiring any LLMs or VLMs in the data creation process. Rather than using models to generate training examples, this experiment algorithmically creates what we hope are realistic learning trajectories that simulate how spatial reasoning competency might develop over time.\nI should note upfront that this approach has obvious limitations. We\u0026rsquo;re essentially creating synthetic behaviors based on assumptions about how learning progresses, rather than capturing actual model failures and improvements. Whether this translates to meaningful training signal remains an open question that Part 2 of this series will attempt to address.\nNote: This is Part 1 of a two-part series focusing on the data generation methodology. Part 2 will cover model training and evaluation results, assuming they\u0026rsquo;re worth sharing.\nThe Challenge with Current Approaches Most spatial reasoning datasets suffer from significant limitations, though I should acknowledge that each approach has valid use cases. LLM-generated data requires expensive API costs for large-scale generation, introduces model bias in generated examples, and makes it difficult to control specific failure patterns (though it does capture more naturalistic language patterns than synthetic approaches). Vision-language models create dependencies on complex visual processing pipelines that are computationally expensive, but they do ground reasoning in actual visual understanding rather than tokenized abstractions. Manual annotation approaches are time-intensive and difficult to scale, but they provide the most authentic human reasoning patterns.\nThe approach described here attempts to sidestep these issues, though it likely introduces new problems of its own.\nMethodology Curriculum Framework Design The framework implements five distinct difficulty levels, each representing what I hypothesize might be different stages of spatial reasoning competency. This is admittedly based on intuition rather than empirical study of how models actually learn spatial tasks.\nLevel 1 simulates initial learning with 5% prediction accuracy, 50% invalid move probability, and 5-step spatial errors from actual positions. The strategy focuses on random exploration with high error rates (though real novice behavior might be even more chaotic than this simplified model suggests). Level 2 introduces basic pattern recognition with 15% accuracy and directional bias emerging after turn 3. Level 3 develops intermediate planning capabilities using single waypoint-based navigation with 25% accuracy. Level 4 advances to dual waypoint planning with oscillation detection, achieving 50% accuracy with zero invalid moves in final turns. Level 5 represents expert performance with perfect A* pathfinding, 100% prediction accuracy, and zero spatial errors.\nThe progression assumes a roughly linear improvement in spatial capabilities, which may not reflect how models actually develop these skills. Real learning curves are likely more jagged, with sudden improvements and occasional regressions that this framework doesn\u0026rsquo;t capture.\nData Generation Process Each level generates conversational exchanges between human (maze state) and assistant (navigation response). The assistant\u0026rsquo;s reasoning process includes spatial analysis of current position and target direction, multi-step move planning with appropriate error injection, level-appropriate motivation and strategy selection, move validity checking with position updates, and reflection generation analyzing prediction accuracy and learning progress.\nProgressive Distribution The curriculum uses a dynamic distribution across 100,000 training samples:\nSamples 0-10k: 60% Level 1, 20% Level 2, declining higher levels Samples 10k-40k: Gradual shift toward intermediate levels Samples 40k-60k: Balanced distribution favoring Levels 2-3 Samples 60k-80k: Emphasis on Levels 3-4 with emerging Level 5 Samples 80k-100k: 60% Level 5, 40% Level 4, minimal lower levels Implementation Details Maze Environment The system uses a grid-based maze representation with:\nRandomized maze generation using depth-first search Configurable sizes (4x4 to 8x8 grids) Token-based representation: \u0026lt;|row-col|\u0026gt;, \u0026lt;|up_down_wall|\u0026gt;, \u0026lt;|origin|\u0026gt;, \u0026lt;|target|\u0026gt; Guaranteed solvability with optimal path lengths between 10-20 moves Behavior Modeling Rather than capturing actual model outputs, the system generates hypothetical learning behaviors:\n# Example: Level 3 waypoint strategy def generate_waypoint_moves(self, maze, waypoint_metadata, current_target, turn): if current_target == \u0026#39;midpoint1\u0026#39;: target_pos = waypoint_metadata[\u0026#39;midpoint1\u0026#39;][\u0026#39;position\u0026#39;] else: target_pos = maze.target # Calculate directional bias toward current objective dr = target_pos[0] - current_pos[0] dc = target_pos[1] - current_pos[1] # Generate bias probabilities bias = self._calculate_directional_bias(dr, dc) return maze.do_random_walk( p=bias, num_steps=5, invalid_chance=self.invalid_chances[turn] ) Conversation Structure Each training sample contains:\nInitial maze state (tokenized representation) Multi-turn conversation (up to 5 turns) Progressive reasoning (improving prediction accuracy) Strategic evolution (from random to optimal planning) Success tracking (target achievement metrics) Key Advantages (and Their Limitations) This approach does offer some practical benefits over model-dependent generation. It eliminates the need for reinforcement learning training loops, policy optimization algorithms, large-scale model checkpointing, and extensive hyperparameter tuning. The synthetic generation allows precise control over error patterns and frequencies, strategic complexity progression, learning curve steepness, and failure mode representation. The framework supports unlimited data generation, diverse maze configurations, configurable difficulty progressions, and multi-domain adaptation potential.\nHowever, these advantages come with significant trade-offs. The precision of control might actually be a weakness, afterall real learning is messier and less predictable than these neat progressions suggest. The unlimited data generation capability is only valuable if the generated data actually teaches useful patterns, which remains to be validated. Most importantly, this approach assumes we understand how spatial reasoning develops well enough to simulate it convincingly, which is probably overconfident.\nExperimental Validation Dataset Characteristics Generated dataset contains:\n100,000 complete maze-solving conversations Average 3.8 turns per conversation (range: 1-5) Behavioral Authenticity The contrast between curriculum levels demonstrates realistic learning progression:\nLevel 1 Example - Spatial Reasoning Breakdown:\nPrediction: \u0026#34;I think I\u0026#39;ll end up at \u0026lt;0-0\u0026gt;\u0026#34; Reality: Ends at \u0026lt;1-1\u0026gt; Moves: \u0026lt;|right|\u0026gt; \u0026lt;|left|\u0026gt; \u0026lt;|right|\u0026gt; \u0026lt;|left|\u0026gt; \u0026lt;|up|\u0026gt; (oscillatory, inefficient) Invalid attempts: Multiple failed \u0026lt;|down|\u0026gt; moves due to walls Strategy: \u0026#34;Let me map out the surrounding area\u0026#34; (confused exploration) Level 5 Example - Expert Performance:\nPrediction: \u0026#34;I think I\u0026#39;ll end up at \u0026lt;4-1\u0026gt;\u0026#34; Reality: \u0026#34;Perfect! I\u0026#39;m exactly at \u0026lt;4-1\u0026gt; - execution was flawless\u0026#34; Moves: Optimal A* pathfinding with dual waypoint strategy Invalid attempts: Zero - all moves valid Strategy: \u0026#34;Looking ahead, I can see position \u0026lt;4-0\u0026gt; is only 3 moves from target\u0026#34; This progression from chaotic spatial confusion to perfect navigation demonstrates:\nRealistic error patterns decreasing over curriculum levels Natural language variation reflecting competency changes Strategic evolution from random exploration to optimal planning Authentic learning trajectory simulation What Would Probably Be Better A more rigorous approach would likely combine elements from multiple methodologies. Ideally, we\u0026rsquo;d start with actual model behavior‚Äîtraining models on spatial tasks and carefully analyzing their failure modes, learning progressions, and breakthrough moments. This would provide empirical grounding for curriculum design rather than relying on assumptions.\nIncorporating human learning data would add another valuable dimension. How do humans develop spatial reasoning skills? What kinds of mistakes do they make, and how do those mistakes change over time? Cognitive science research on spatial learning could inform more realistic error patterns and progression rates.\nA hybrid approach might prove most effective: use LLMs to generate diverse initial examples, analyze real model failures to understand authentic confusion patterns, then use deterministic generation to scale up the most informative training scenarios. This would combine the naturalistic language of LLM generation, the authenticity of real model behavior, and the control and scalability of synthetic approaches.\nFor validation, we\u0026rsquo;d want to compare not just final task performance but also the learning dynamics‚Äîdo models trained on this synthetic curriculum develop spatial reasoning in similar ways to models trained through direct experience or human demonstration?\nFuture Directions Dataset and Model Release The complete dataset and models trained on this curriculum framework will be released in the coming months, including:\nFull 100,000-sample training dataset with all curriculum levels Detailed methodology documentation and generation code Evaluation benchmarks for spatial reasoning tasks Conclusion This deterministic approach to spatial reasoning data generation represents an experiment in algorithmic curriculum design rather than a definitive solution. While it offers practical advantages over LLM-based or VLM-dependent methods through cost efficiency with no API calls or GPU-intensive model inference required, precise control over learning progression and error patterns, unlimited scalability with consistent quality, and complete transparency in understanding how each training example was created, these benefits may be offset by the artificial nature of the generated learning trajectories.\nThe framework demonstrates that it may be possible to create structured spatial reasoning training data through pure algorithmic generation, but whether this data actually improves model performance remains an empirical question. The approach might work well as a starting point or supplement to other training data, even if it doesn\u0026rsquo;t fully replace more authentic alternatives.\nThe real test will be whether models trained on this curriculum develop generalizable spatial reasoning skills or simply learn to mimic the specific patterns encoded in the synthetic data. Part 2 will attempt to provide some preliminary answers, though a comprehensive evaluation would require much more extensive experimentation than a single project can provide.\nComing Next: Part 2 of this series will cover training language models on this curriculum dataset and evaluating their spatial reasoning capabilities, assuming the results are interesting enough to warrant sharing.\nThe complete dataset generation framework will be released regardless of training outcomes, as the methodology itself may be of interest even if the results are disappointing. For questions about the approach or early access to the dataset, please reach out through [amanpriyanshu.github.io].\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2025/mazesolver-grpo-data/","summary":"\u003cp\u003e\u003cstrong\u003eQuick Links:\u003c/strong\u003e\n\u003ca href=\"https://github.com/AmanPriyanshu/Tiny-Maze-Mock-GRPO\"\u003eGitHub Repository\u003c/a\u003e | \u003ca href=\"https://huggingface.co/datasets/AmanPriyanshu/Tiny-Maze-Mock-GRPO\"\u003eDataset Sample\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eSpatial reasoning remains a significant challenge for language models, particularly in tasks requiring 2D navigation and visual-spatial understanding. Current approaches typically rely on either training large vision-language models (VLMs) on visual data or using language models to generate training examples through expensive API calls.\u003c/p\u003e\n\u003cp\u003eThis post explores what might be considered an unconventional (and possibly naive) approach: \u003cstrong\u003edeterministic generation of spatial reasoning data\u003c/strong\u003e without requiring any LLMs or VLMs in the data creation process. Rather than using models to generate training examples, this experiment algorithmically creates what we hope are realistic learning trajectories that simulate how spatial reasoning competency might develop over time.\u003c/p\u003e","title":"Creating 2D Spatial Reasoning Data Without LLMs / VLMs: A Deterministic Curriculum Trial"},{"content":"Quick Links: Dataset on HuggingFace\nThe Topic Modeling Challenge You know that feeling when you have 50 browser tabs open, and you\u0026rsquo;re desperately trying to organize them into bookmark folders? \u0026ldquo;ML Papers To Read,\u0026rdquo; \u0026ldquo;Funny Cat Videos,\u0026rdquo; \u0026ldquo;Recipes I\u0026rsquo;ll Never Make\u0026rdquo;\u0026hellip; We all have our system. And apparently, it\u0026rsquo;s such a universal problem that every tech company is launching their own solution - Arc Browser with its \u0026ldquo;Spaces,\u0026rdquo; Chrome with its tab groups, and about 500 extensions promising to color-code your digital hoarding habits into submission.\nNow imagine doing this with millions of documents - that\u0026rsquo;s basically what topic modeling is about. And if you\u0026rsquo;re like me, your bookmark folders have subfolders, which have more subfolders (yes, I may have a problem), because sometimes \u0026ldquo;ML Papers\u0026rdquo; needs to be split into \u0026ldquo;Transformers,\u0026rdquo; \u0026ldquo;Computer Vision,\u0026rdquo; and \u0026ldquo;That One Attention Is All You Need Paper That Everyone References But Only Read The Abstract And Figure 3\u0026rdquo; (you know exactly which paper I\u0026rsquo;m talking about).\nThat\u0026rsquo;s where dynamic topic modeling comes in - it\u0026rsquo;s like having an AI assistant that not only organizes your content into folders but also creates a hierarchy that actually makes sense. No more \u0026ldquo;Misc\u0026rdquo; folders with 500 unrelated bookmarks! See, working with large text collections presents a unique challenge: how do you effectively understand and organize content at scale? Traditional approaches like LDA (Latent Dirichlet Allocation) often fall short, producing cryptic word clusters that require significant human interpretation. Meanwhile, newer transformer-based approaches demand substantial computational resources. That\u0026rsquo;s where I\u0026rsquo;d like to introduce: Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens, a dataset for dyanmic topic modeling.\nA Different Approach to Topic Modeling This project introduces a unique solution: a hierarchical topic modeling dataset built on a subset of RedPajama. Instead of relying solely on statistical methods, I leveraged the semantic understanding capabilities of language models to create rich, multi-level topic annotations.\nThe result? A dataset featuring:\n100,000 diverse text samples Three levels of topic granularity Rich topic diversity with: 25,178 distinct level-1 topics (broad categories) 71,024 distinct level-2 topics (specific domains) 92,568 distinct level-3 topics (detailed subjects) How It Works The process involved several key steps:\nData Selection: Carefully sampled 100k documents from RedPajama, ensuring representation across different content types.\nPreprocessing:\ndef prepare_document(text): encoded = tokenizer(text, truncation=True, max_length=1024) return encoded Topic Generation: Used GPT-4o-mini to generate hierarchical topics: { \u0026#34;text\u0026#34;: \u0026#34;Original document text...\u0026#34;, \u0026#34;topic_level_1\u0026#34;: \u0026#34;Academic Research\u0026#34;, \u0026#34;topic_level_2\u0026#34;: \u0026#34;Machine Learning Applications\u0026#34;, \u0026#34;topic_level_3\u0026#34;: \u0026#34;Neural Network Architectures for NLP\u0026#34; } Why This Matters This dataset addresses several key needs:\nResearch Reproducibility: Provides a standardized dataset for benchmarking dyanmic topic modeling approaches\nHierarchical Understanding: Enables analysis at multiple levels of granularity\nTraining Data: Perfect for fine-tuning smaller models for topic prediction. Previously, I\u0026rsquo;ve worked on transformer-models for dynamic topic-modeling, however, lacked a well-defined dataset which this fills.\nContent Organization: Helps build better document classification systems\nPractical Applications Because who doesn\u0026rsquo;t love a good TL;DR:\nModel Training: Teaching smaller models to be topic-spotting ninjas Content Analysis: Finally figuring out what\u0026rsquo;s in those 10,000 open browser tabs Memory Optimization: Making large-scale topic modeling possible without setting your laptop on fire Hierarchical Relations: Building family trees for topics (minus the awkward reunions) Cross-Domain Analysis: Understanding how topics relate across different fields (spoiler: everything eventually leads to cats) Future Directions The fun doesn\u0026rsquo;t stop here:\nCross-lingual Extension: Teaching AI to be multilingual without using Google Translate Temporal Analysis: Understanding how topics evolve (like fashion, but for words) Domain Adaptation: Making the model work everywhere from Shakespeare to TikTok comments Real-time Processing: Topic modeling at the speed of Twitter drama Interactive Visualization: Making pretty graphs that actually mean something The Path Forward The dataset demonstrates the power of combining traditional NLP techniques with modern language models. Whether you\u0026rsquo;re building a document classification system, conducting research, or just exploring topic modeling, this dataset can provide a solid foundation for dynamic topic generation.\nP.S. If you\u0026rsquo;re also obsessed with making sense of text data or just want to share your own \u0026ldquo;teaching AI to read\u0026rdquo; horror stories, hit me up at amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s make topic modeling fun again! üöÄü§ñüìö\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/dynamic-topic-modeling/","summary":"\u003cp\u003e\u003cstrong\u003eQuick Links:\u003c/strong\u003e\n\u003ca href=\"https://huggingface.co/datasets/AmanPriyanshu/Dynamic-Topic-RedPajama-Data-1T-100k-SubSample-max-1k-tokens\"\u003eDataset on HuggingFace\u003c/a\u003e\u003c/p\u003e\n\u003cdiv style=\"display: flex; justify-content: space-between;\"\u003e\n  \u003cimg src=\"https://raw.githubusercontent.com/AmanPriyanshu/blogs/refs/heads/main/content/posts/2024/Dynamic-Topic-Modeling/images/dynamic-topics-banner.png\" alt=\"Dynamic Topic Modeling\" style=\"width: 96%;\"/\u003e\n\u003c/div\u003e\n\u003ch2 id=\"the-topic-modeling-challenge\"\u003eThe Topic Modeling Challenge\u003c/h2\u003e\n\u003cp\u003eYou know that feeling when you have 50 browser tabs open, and you\u0026rsquo;re desperately trying to organize them into bookmark folders? \u0026ldquo;ML Papers To Read,\u0026rdquo; \u0026ldquo;Funny Cat Videos,\u0026rdquo; \u0026ldquo;Recipes I\u0026rsquo;ll Never Make\u0026rdquo;\u0026hellip; We all have our system. And apparently, it\u0026rsquo;s such a universal problem that every tech company is launching their own solution - Arc Browser with its \u0026ldquo;Spaces,\u0026rdquo; Chrome with its tab groups, and about 500 extensions promising to color-code your digital hoarding habits into submission.\u003c/p\u003e","title":"Teaching AI to Read and Group Like I Bookmark the Web: A Journey into Dynamic Topic Modeling"},{"content":"Quick Links: Model on HuggingFace | Interactive Demo\nWhen it comes to topic extraction, the AI world seems fixated on massive models and expensive compute. But what if there was a simpler way? ü§î\nThe Genesis: Simplicity Through Linear Transformation Picture this: There I was, looking for an open-source solution to extract topics from text at scale. The available options were either massive language models or complex fine-tuning pipelines. That\u0026rsquo;s when it hit me ‚Äì what if we could leverage the semantic structure of existing embeddings with just a linear transformation?\nThe Architecture: Elegant in Its Simplicity The solution combines three key components:\nBottleneck T5 Large as our backbone (credit to @thesephist) Domain-specific 1024√ó1024 transformation matrices A straightforward mapping from content to topic space What makes this approach powerful is its minimal computational footprint combined with surprising effectiveness.\nThe Numbers That Matter Here\u0026rsquo;s how it performs across different domains:\nDataset Training MSE Testing MSE Inter-topic MSE ArXiv 0.00225 0.00268 0.00620 TopicSUM 0.00252 0.00255 0.00737 MSD 0.00174 0.00197 0.00566 These metrics show consistent performance across domains while maintaining clear topic separation.\n* Edit: I recently created a dataset for dynamic topic modeling with more diverse content sources. Check out the blog about this 100K-document hierarchical dataset here\nImplementation: Straightforward and Efficient Here\u0026rsquo;s a complete example of how to use the model:\nimport torch import requests from transformers import AutoTokenizer, AutoModelForCausalLM class BottleneckT5Autoencoder: def __init__(self, model_path: str, device=\u0026#39;cpu\u0026#39;): self.device = device self.tokenizer = AutoTokenizer.from_pretrained(model_path, model_max_length=512) self.model = AutoModelForCausalLM.from_pretrained( model_path, trust_remote_code=True ).to(device) self.model.eval() def embed(self, text: str) -\u0026gt; torch.FloatTensor: inputs = self.tokenizer(text, return_tensors=\u0026#39;pt\u0026#39;).to(self.device) decoder_inputs = self.tokenizer(\u0026#39;\u0026#39;, return_tensors=\u0026#39;pt\u0026#39;).to(self.device) return self.model( **inputs, decoder_input_ids=decoder_inputs[\u0026#39;input_ids\u0026#39;], encode_only=True, )[0] def generate_from_latent(self, latent: torch.FloatTensor, max_length=512): dummy_text = \u0026#39;.\u0026#39; dummy = self.embed(dummy_text) perturb_vector = latent - dummy self.model.perturb_vector = perturb_vector input_ids = self.tokenizer(dummy_text, return_tensors=\u0026#39;pt\u0026#39;).to(self.device).input_ids output = self.model.generate( input_ids=input_ids, max_length=max_length, do_sample=True, temperature=1.0, top_p=0.9, num_return_sequences=1, ) return self.tokenizer.decode(output[0], skip_special_tokens=True) # Load model and transformation matrix model_path = \u0026#34;AmanPriyanshu/Contra-Topic-bottleneck-t5-large\u0026#34; matrix_url = \u0026#39;https://huggingface.co/AmanPriyanshu/Contra-Topic-bottleneck-t5-large/resolve/main/transformation_matrix_arxiv.pt\u0026#39; autoencoder = BottleneckT5Autoencoder(model_path=model_path) transformation_matrix = torch.load( requests.get(matrix_url).content, weights_only=False ).float() # Extract topic from content content = \u0026#34;Your text here...\u0026#34; content_embedding = autoencoder.embed(content) topic_embedding = content_embedding @ transformation_matrix topic = autoencoder.generate_from_latent(topic_embedding) print(f\u0026#34;Extracted topic: {topic}\u0026#34;) Why This Matters The advantages of this approach are clear:\nSub-second inference times Minimal memory requirements (~4MB per domain) No cloud computing dependencies Transparent transformation process Current Limitations Let\u0026rsquo;s be clear about what this model can and can\u0026rsquo;t do:\nDomain Specificity: Each transformation matrix is optimized for its specific domain (provided ArXiv (Research), MSD (Medical), and TopicSum (Dialogues) ) Fixed Dimensionality: The approach is constrained to Bottleneck T5\u0026rsquo;s 1024D embedding space Linear Transformation Limits: We assume a linear relationship between content and topic spaces Future Directions There\u0026rsquo;s still plenty of room for improvement:\nInvestigating non-linear transformations for complex topic relationships Developing domain adaptation techniques Exploring dimension reduction possibilities Conclusion: Efficiency Through Simplicity This project demonstrates that effective topic extraction doesn\u0026rsquo;t always require massive models or expensive compute. Through careful use of linear transformations and existing embeddings, we can achieve practical results with minimal resources.\nIs it perfect? No. But it offers a pragmatic solution for those needing efficient, scalable topic extraction without the computational overhead of larger language models.\nP.S. If you\u0026rsquo;re interested in exploring this approach further or have ideas for improvements, feel free to reach out at amanpriyanshusms2001[at]gmail[dot]com. The best solutions often come from collaborative thinking! üöÄ‚ú®\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/contra-topic/","summary":"\u003cp\u003e\u003cstrong\u003eQuick Links:\u003c/strong\u003e\n\u003ca href=\"https://huggingface.co/AmanPriyanshu/Contra-Topic-bottleneck-t5-large\"\u003eModel on HuggingFace\u003c/a\u003e | \u003ca href=\"https://colab.research.google.com/drive/1_SuTiL3QS-PUYjSrugqqD5mQlMv8Hbfc?usp=sharing\"\u003eInteractive Demo\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWhen it comes to topic extraction, the AI world seems fixated on massive models and expensive compute. But what if there was a simpler way? ü§î\u003c/p\u003e\n\u003cdiv style=\"display: flex; justify-content: space-between;\"\u003e\n  \u003cimg src=\"https://raw.githubusercontent.com/AmanPriyanshu/blogs/refs/heads/main/content/posts/2024/Contra-Topic/images/contra-topic-banner.png\" alt=\"Topic Modeling\" style=\"width: 96%;\"/\u003e\n\u003c/div\u003e\n\u003ch2 id=\"the-genesis-simplicity-through-linear-transformation\"\u003eThe Genesis: Simplicity Through Linear Transformation\u003c/h2\u003e\n\u003cp\u003ePicture this: There I was, looking for an open-source solution to extract topics from text at scale. The available options were either massive language models or complex fine-tuning pipelines. That\u0026rsquo;s when it hit me ‚Äì what if we could leverage the semantic structure of existing embeddings with just a linear transformation?\u003c/p\u003e","title":"Contra-Topic-bottleneck-t5: Efficient Topic Extraction Without the Computational Overhead"},{"content":"Hey there, optimization seekers and efficiency enthusiasts! üìäüßÆ Today, we\u0026rsquo;re diving into a world where even basic arithmetic operations are up for debate. Buckle up as we explore LinearCosine, an experiment that asks: \u0026ldquo;Do we really need multiplication for AI?\u0026rdquo;\nQuick Links to skip the talk: Project Website - Linear Cosine | GitHub Repo | Original Paper\nThe Paper That Started It All During my fall break, while I was supposed to be relaxing, my roommate Yash Maurya forwarded me a fascinating paper by Hongyin Luo and Wei Sun titled \u0026ldquo;Addition is All You Need for Energy-efficient Language Models\u0026rdquo;. I was immediately intrigued by their approach to modify one of the core fundamental computations in AI, multiplication. This project builds upon my previous work on in-browser vanilla js semantic search, such as YC-Dendrolinguistics, where I implemented a cosine similarity-based information retrieval system for YC startups. LinearCosine takes this a step further by exploring ways to make these fundamental calculations more energy-efficient.\nWhat is LinearCosine? LinearCosine is my experimental project to explore the potential of the L-Mul algorithm for energy-efficient cosine similarity calculations. Here\u0026rsquo;s what it\u0026rsquo;s all about:\nL-Mul Algorithm Implementation: Adapting Luo and Sun\u0026rsquo;s approach for cosine similarity. Cosine Similarity Optimization: Applying this method to a common calculation in AI and ML. Comprehensive Benchmarking: Rigorously testing the performance against traditional methods. The Math Behind the Madness Let\u0026rsquo;s break down the key mathematical concepts:\nStandard Floating-Point Multiplication The traditional method multiplies two floating-point numbers as follows:\nMul(x,y) = (1 + x_m) * 2^(x_e) * (1 + y_m) * 2^(y_e) = (1 + x_m + y_m + x_m * y_m) * 2^(x_e + y_e) Where x_m and y_m are mantissas, and $x_e$ and $y_e$ are exponents.\nL-Mul Algorithm The L-Mul method approximates this multiplication:\nL-Mul(x,y) = (1 + x_m + y_m + 2^(-l(m))) * 2^(x_e + y_e) Where l(m) is defined as:\nl(m) = m if m ‚â§ 3 l(m) = 3 if m = 4 l(m) = 4 if m \u0026gt; 4 Here, m represents the number of mantissa bits.\nThe Experiment In LinearCosine, I implemented the L-Mul algorithm and applied it to cosine similarity calculations. I then conducted extensive benchmarking to compare its performance and accuracy against traditional floating-point multiplication.\nResults: Efficiency Meets Accuracy Here\u0026rsquo;s one of the tables from the experiments: The table below illustrates the performance of cosine similarity calculations using different levels of mantissa precision. The L-Mul approach achieves significant time reduction while maintaining an acceptable mean squared error (depends on your usecase), making it a fast and efficient approximation for high-speed computations.\nMantissa Bits L-Mul MSE L-Mul Time (ns) Mul MSE Mul Time (ns) Time Reduction (%) 2 9.45862e-06 507 4.07024e-08 670 24.3284% 3 1.84347e-05 459 4.07024e-08 597 23.1156% 4 1.84347e-05 383 4.07024e-08 516 25.7752% 5 4.44707e-05 477 1.93169e-06 629 24.1653% 6 1.78036e-05 477 6.42665e-08 625 23.68% 7 2.11236e-05 498 2.21875e-08 654 23.8532% 8 2.0259e-05 442 1.28071e-09 589 24.9576% 9 1.9652e-05 460 6.87609e-09 607 24.2175% 10 1.84467e-05 444 7.4093e-10 588 24.4898% 11 1.82827e-05 506 6.00017e-10 669 24.3647% 12 1.80075e-05 433 1.11101e-10 572 24.3007% 13 1.79965e-05 487 1.01831e-10 643 24.2613% 14 1.79698e-05 494 2.53293e-11 657 24.8097% 15 1.79675e-05 460 1.13981e-12 609 24.4663% 16 1.79675e-05 386 1.02339e-12 520 25.7692% 17 1.79673e-05 435 3.19744e-14 580 25.0% 18 1.79673e-05 396 3.19744e-14 532 25.5639% 19 1.79673e-05 402 1.42109e-14 539 25.4174% 20 1.79673e-05 496 0 651 23.8095% 21 1.79673e-05 477 0 627 23.9234% 22 1.79673e-05 431 0 572 24.6503% 23 1.79673e-05 415 0 555 25.2252% Here\u0026rsquo;s what I found:\n1D to 1D Cosine Similarity:\nAverage time reduction: 24.55% Average L-Mul MSE: 1.9184e-05 1D to 2D Cosine Similarity:\nTime reductions ranging from 16.8% to 18.6% 2D to 2D Cosine Similarity:\nTime reductions between 21.88% and 23.12% Implications and Potential These results open up some interesting possibilities:\nPerformance Boost: The consistent speed improvements could translate to significant efficiency gains in large-scale AI operations. Accuracy-Efficiency Trade-off: While there\u0026rsquo;s a slight loss in accuracy, it\u0026rsquo;s within acceptable limits for many AI applications. Energy Efficiency Potential: The reduced computation time hints at possible energy savings, though this would need further investigation on actual hardware. Limitations and Considerations It\u0026rsquo;s important to acknowledge the limitations of this experiment:\nThis is a simplified implementation and may not capture all nuances of the original proposal. The benchmarks focus on raw computation time, which doesn\u0026rsquo;t directly translate to energy efficiency in real-world scenarios. Results may vary significantly in different hardware environments or more complex applications. Future Directions This experiment opens up several exciting avenues for further exploration:\nHardware-Specific Implementation: Testing on specialized hardware could provide more realistic efficiency metrics and potentially uncover even greater performance gains. Detailed Energy Consumption Analysis: Conducting studies with actual energy consumption measurements to quantify the potential energy savings in real-world scenarios. Optimization for Different Precision Levels: Investigating how the L-Mul algorithm performs under different precision requirements and optimizing it for specific use cases. Integration with Existing AI Frameworks: Exploring ways to integrate this approach into popular AI frameworks to make it more accessible to researchers and practitioners. Acknowledgments All credit for the L-Mul algorithm and its theoretical foundations goes to Hongyin Luo and Wei Sun, as presented in their 2024 paper. This benchmark is an independent exploration of their concepts and should not be considered an official implementation or extension of their work.\nCitation @misc{luo2024additionneedenergyefficientlanguage, title={Addition is All You Need for Energy-efficient Language Models}, author={Hongyin Luo and Wei Sun}, year={2024}, eprint={2410.00907}, archivePrefix={arXiv}, primaryClass={cs.CL}, url={https://arxiv.org/abs/2410.00907}, } Disclaimer This project is for educational purposes only. It is not intended for production use and does not claim to accurately represent the full potential or limitations of the L-Mul algorithm as proposed by Luo and Sun. You are encouraged to refer to the original paper for authoritative information.\nWrapping Up: A Step Towards Efficient AI LinearCosine represents a small but interesting step in the quest for more efficient AI computations. While it may not revolutionize the field overnight, it demonstrates the potential benefits of rethinking fundamental operations in AI models.\nIs LinearCosine going to revolutionize the AI world? Probably not. But it\u0026rsquo;s a fun exploration into the kinds of optimizations that could shape the future of energy-efficient AI. And if nothing else, it\u0026rsquo;s a great story for your next hackathon.\nP.S. If you\u0026rsquo;ve explored similar optimization techniques or have insights on energy-efficient AI computations, I\u0026rsquo;d love to hear about it! Or if you have ideas on how to extend this experiment, feel free to reach out. You can contact me at amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s continue pushing the boundaries of AI efficiency together! üöÄüß†üí°\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/linear-cosine/","summary":"\u003cp\u003eHey there, optimization seekers and efficiency enthusiasts! üìäüßÆ Today, we\u0026rsquo;re diving into a world where even basic arithmetic operations are up for debate. Buckle up as we explore \u003ca href=\"https://amanpriyanshu.github.io/LinearCosine/\"\u003eLinearCosine, an experiment that asks: \u0026ldquo;Do we really need multiplication for AI?\u0026rdquo;\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eQuick Links to skip the talk:\u003c/strong\u003e\n\u003ca href=\"https://amanpriyanshu.github.io/LinearCosine/\"\u003eProject Website - Linear Cosine\u003c/a\u003e | \u003ca href=\"https://github.com/AmanPriyanshu/LinearCosine\"\u003eGitHub Repo\u003c/a\u003e | \u003ca href=\"https://arxiv.org/abs/2410.00907\"\u003eOriginal Paper\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"the-paper-that-started-it-all\"\u003eThe Paper That Started It All\u003c/h2\u003e\n\u003cp\u003eDuring my fall break, while I was supposed to be relaxing, my roommate Yash Maurya forwarded me a fascinating paper by Hongyin Luo and Wei Sun titled \u0026ldquo;\u003ca href=\"https://arxiv.org/abs/2410.00907\"\u003eAddition is All You Need for Energy-efficient Language Models\u003c/a\u003e\u0026rdquo;. I was immediately intrigued by their approach to modify one of the core fundamental computations in AI, multiplication. This project builds upon my previous work on \u003ca href=\"https://amanpriyanshu.github.io/blogs/posts/2024/startup-linguistic-trees/\"\u003ein-browser vanilla js semantic search, such as YC-Dendrolinguistics\u003c/a\u003e, where I implemented a \u003ca href=\"https://amanpriyanshu.github.io/YC-Dendrolinguistics/\"\u003ecosine similarity-based information retrieval system for YC startups\u003c/a\u003e. LinearCosine takes this a step further by exploring ways to make these fundamental calculations more energy-efficient.\u003c/p\u003e","title":"LinearCosine: When AI Researchers Decided Multiplication was Too Mainstream"},{"content":" Quick links (in case you want to skip my ramblings):\nPyPI Package GitHub Repository\nAlright, gather \u0026lsquo;round, word enthusiasts and syntax sorcerers! üßô‚Äç‚ôÇÔ∏èüìö Remember that time you tried to explain machine learning to your grandma and ended up comparing neural networks to her knitting patterns? Well, buckle up, because we\u0026rsquo;re about to dive into a similar realm of \u0026ldquo;What was I thinking?\u0026rdquo; ‚Äì the saga of AdaptKeyBERT.\nIt\u0026rsquo;s been two trips around the sun since I cobbled together this quirky little keyword extractor and sent it off into the wild world of NLP. And by \u0026ldquo;sent it off,\u0026rdquo; I mean I uploaded it to GitHub, patted myself on the back, and promptly got distracted by the next shiny AI puzzle (it was differential privacy and most recently extracting linguistic patterns from startup pitch decks). Classic.\nWhat in the Name of Turing is AdaptKeyBERT? For those of you who, like me, need a refresher (because who remembers what they coded two years ago!), AdaptKeyBERT is this simple-to-use contraption that\u0026rsquo;s supposed to pull keywords out of text. Here\u0026rsquo;s what it allegedly does:\nDomain Adaptability: It tries to understand field-specific jargon without having a meltdown. Few-Shot Learning: Because sometimes you only have like three examples and a prayer. Zero-Shot Capabilities: For when you\u0026rsquo;re feeling especially optimistic about AI\u0026rsquo;s mind-reading abilities. Surprising Signs of Life So, get this ‚Äì apparently, while I\u0026rsquo;ve been off trying to teach neural networks to be safer against jailbreaks, AdaptKeyBERT has been doing\u0026hellip; stuff? Real researchers have been using it. Let\u0026rsquo;s take a peek at what\u0026rsquo;s been happening:\nA Few Unexpected Mentions Some folks at IEEE gave AdaptKeyBERT a whirl on the DUC2001 dataset. It didn\u0026rsquo;t crash and burn, which is always a plus. (Check it out here)\nThere was this study on legal text classification where AdaptKeyBERT somehow didn\u0026rsquo;t embarrass itself completely. Zero-shot and still kicking? Color me surprised. (See for yourself)\nApparently, people are using it to analyze central banker speeches. (Economic adventure here)\nWhat\u0026rsquo;s Next? (Besides Actually Working on It Again) Look, I\u0026rsquo;m as surprised as anyone that AdaptKeyBERT is still chugging along. Since it seems determined to stick around, maybe we should think about where it could go next:\nMultilingual Mayhem: Teaching it to extract keywords in multiple languages. What could possibly go wrong? Although, this is probably already handled by its zero-shot functionality, just needs benchmarking.\nLLM Collaboration: Teaming up with large language models. Maybe they can explain to AdaptKeyBERT what it\u0026rsquo;s supposed to be doing.\nBrowser-Based Brainiac: Unleashing a Vanilla JS version that turns your browser into a keyword-crunching machine. Because who needs server-side processing when you can make your laptop fans sound like a jet engine?\nWrapping Up: The Accidental Adventure Continues Well, there you have it. AdaptKeyBERT: the little keyword extractor that could (sometimes). It\u0026rsquo;s been a wild ride watching this digital child of mine stumble through the NLP world while I wasn\u0026rsquo;t looking.\nWho knows what the future holds for AdaptKeyBERT? More academic citations? Skynet? An identity crisis? Only time will tell.\nP.S. If you\u0026rsquo;ve somehow used AdaptKeyBERT in your work and it didn\u0026rsquo;t set your research back by years, I\u0026rsquo;d love to hear about it! Or if you have ideas on how to make it less of a hot mess, I\u0026rsquo;m all ears. You can reach me at amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s continue to stumble forward in the name of science! üöÄü§™üß†\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/adaptkeybert/","summary":"\u003cdiv style=\"display: flex; justify-content: space-between;\"\u003e\n  \u003cimg src=\"https://amanpriyanshu.github.io/AdaptKeyBERT/images/adaptkeybert_revisited.png\" alt=\"Running Demo 1\" style=\"width: 90%;\"/\u003e\n\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eQuick links (in case you want to skip my ramblings):\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://pypi.org/project/adaptkeybert/\"\u003ePyPI Package\u003c/a\u003e\n\u003ca href=\"https://github.com/AmanPriyanshu/AdaptKeyBERT\"\u003eGitHub Repository\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAlright, gather \u0026lsquo;round, word enthusiasts and syntax sorcerers! üßô‚Äç‚ôÇÔ∏èüìö Remember that time you tried to explain machine learning to your grandma and ended up comparing neural networks to her knitting patterns? Well, buckle up, because we\u0026rsquo;re about to dive into a similar realm of \u0026ldquo;What was I thinking?\u0026rdquo; ‚Äì the saga of AdaptKeyBERT.\u003c/p\u003e","title":"AdaptKeyBERT: Stumbling Through Two Years of Keyword Extraction"},{"content":"Hey there, fellow code enthusiasts and AI wranglers! üñêÔ∏èü§ñ You know that feeling when you\u0026rsquo;re knee-deep in a project, trying to get multiple AI models to play nice in your browser? Yeah, I\u0026rsquo;ve been there. Cue the frustrated sighs, the endless searches over GitHub issues üò¢, and the \u0026ldquo;why-isn\u0026rsquo;t-this-working\u0026rdquo; hair-pulling sessions.\nLINK-TO-PACKAGE just in case you wanna skip the deets\nAfter one too many nights wrestling with backends, CORS issues, and the general chaos of integrating various AI APIs, I decided enough was enough. There had to be a simpler way, right? Something that didn\u0026rsquo;t require installing a bunch of npm builds, juggling APIs, or managing a backend server farm just to get a chatbot running on a static page.\nTurns out, there wasn\u0026rsquo;t a simple solution ‚Äì shocking, I know. So, armed with nothing but sleeplessness and caffeine, I decided to build it myself. Enter API-LLM-Hub: my first rodeo in JavaScript packaging and a testament to what happens when a Python AI nerd ventures into the wild west of front-end development. It\u0026rsquo;s been a painful journey figuring out things which I have kept stalling all through my undergrad. But hey, if I can wrangle this into existence while learning what a promise is, I can probably claim \u0026lsquo;Full-Stack\u0026rsquo; on my resume now! üç™üíªüöÄ\nThe Spark of Inspiration Ever tried juggling multiple AI APIs in a browser? üòÉ\nIt\u0026rsquo;s about as fun as catching Zapdos with a normal ball in FireRed. That\u0026rsquo;s why I cooked up API-LLM-Hub ‚Äì a vanilla JavaScript library that lets you tap into various AI language model APIs right from your browser, no backend required.\nWhat\u0026rsquo;s in the Box? API-LLM-Hub is like that Swiss Army knife you always wished you had for static-page AI development (because who doesn\u0026rsquo;t dream about that, right?). Here\u0026rsquo;s what you\u0026rsquo;re getting:\nBrowser Besties: This thing runs directly in your browser. No server-side shenanigans required! CORS Conqueror: I nearly cried dealing with Anthropic\u0026rsquo;s bizarre API examples‚Äîespecially since they don\u0026rsquo;t have any for CORS issues! Multi-AI Handling: Switch between OpenAI, Anthropic, TogetherAI, and Google\u0026rsquo;s Gemini. Vanilla JS Goodness: No fancy frameworks or build steps. Just pure, unadulterated JavaScript joy. An Example I Wish I\u0026rsquo;d Seen Before Starting This Stupic Project \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import APILLMHub from \u0026#39;https://amanpriyanshu.github.io/API-LLM-Hub/unified-llm-api.js\u0026#39;; async function runTest() { const ai = new APILLMHub({ provider: \u0026#39;openai\u0026#39;, apiKey: \u0026#39;your-api-key\u0026#39;, model: \u0026#39;gpt-3.5-turbo\u0026#39; }); await ai.initialize(); const response = await ai.sendMessage(\u0026#34;Hello, AI!\u0026#34;); console.log(response); } runTest(); \u0026lt;/script\u0026gt; That\u0026rsquo;s it. Seriously. You\u0026rsquo;re now conversing with an AI in your browser.\nWhy You\u0026rsquo;ll Love It (and Why Your Browser Will Too) Static Site Sorcery: GitHub Pages? Netlify? No problem. API-LLM-Hub plays nice with all your favorite static hosts. AI Provider Roulette: AI Provider Roulette: Switch between AI providers with a single line of code‚Äîwell, actually a function call\u0026hellip; okay, maybe just one variable (provider), and possibly another (model). Real-World Magic (Because static pages are just crying out for embedded chatbots, aren\u0026rsquo;t they?) You can now integrate any static page with a chatbot using the user\u0026rsquo;s API keys or add some LLM flair to your browser extension. Since I worked on implementing semantic search over recent YC startup batches in YC-Dendrolinguistics (I highly recommend checking out the Startup Linguistic Trees blog), combining that search with this system could easily implement RAGs (Retrieval-Augmented Generation) on static webpages‚Äîwhich is both crazy and stupid. With API-LLM-Hub, you\u0026rsquo;re only limited by your imagination (and maybe your API usage limits‚Äîbut that\u0026rsquo;s a problem for future you).\nWrapping Up And there you have it, folks‚ÄîAPI-LLM-Hub in all its simplicity. It\u0026rsquo;s a small step towards making LLM-API integration on static pages a bit simpler and a lot more fun. Give it a try!\nP.S. If you found this little AI adventure intriguing (or at least mildly entertaining), stay tuned! There\u0026rsquo;s plenty more where this came from. And hey, if you want to collaborate on some wild browser-based AI experiment, don\u0026rsquo;t hesitate to reach out. My email is still amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s make the web a little smarter together! üåêü§ñüí°\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/api-llm-hub/","summary":"\u003cp\u003eHey there, fellow code enthusiasts and AI wranglers! üñêÔ∏èü§ñ You know that feeling when you\u0026rsquo;re knee-deep in a project, trying to get multiple AI models to play nice in your browser? Yeah, I\u0026rsquo;ve been there. Cue the frustrated sighs, the endless searches over GitHub issues üò¢, and the \u0026ldquo;why-isn\u0026rsquo;t-this-working\u0026rdquo; hair-pulling sessions.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://amanpriyanshu.github.io/API-LLM-Hub/\"\u003e\u003cstrong\u003eLINK-TO-PACKAGE\u003c/strong\u003e\u003c/a\u003e \u003cstrong\u003ejust in case you wanna skip the deets\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAfter one too many nights wrestling with backends, CORS issues, and the general chaos of integrating various AI APIs, I decided enough was enough. There had to be a simpler way, right? Something that didn\u0026rsquo;t require installing a bunch of npm builds, juggling APIs, or managing a backend server farm just to get a chatbot running on a static page.\u003c/p\u003e","title":"API-LLM-Hub: Simplifying LLM-API integration for Static Pages"},{"content":"Hey there, fellow AI adventurers and startup enthusiasts! üå≥üöÄ Today, I\u0026rsquo;m excited to give you a peek into my latest passion project: YC-Dendrolinguistics. Buckle up as we embark on a journey through the linguistic forests of Y-Combinator pitches!\nThe Seed of an Idea Picture this: It\u0026rsquo;s 2 AM, I\u0026rsquo;m knee-deep in YC application videos, and suddenly it hits me ‚Äì what if startup pitches are like trees? ü§î Each word a branch, each phrase a limb, growing into this complex organism we call a pitch. That\u0026rsquo;s when YC-Dendrolinguistics was born, my wild attempt to map the DNA of startup communication.\nCultivating the Startup Vocabulary So, what exactly am I doing? Well, imagine if David Attenborough decided to narrate a nature documentary about startup pitches instead of penguins. That\u0026rsquo;s basically me, minus the soothing accent. I\u0026rsquo;m analyzing YC startup descriptions, breaking them down to their roots, and seeing what kind of linguistic forest they create.\nHere\u0026rsquo;s what\u0026rsquo;s growing in our little experiment:\nPitch Decomposition: Slicing and dicing startup pitches into their fundamental components. It\u0026rsquo;s like linguistic bonsai, but with more buzzwords. Grammar Trees: Creating tree structures that represent pitch patterns. Theme Spotting: Hunting for common elements across pitches. Data Visualization: Turning all this linguistic madness into pretty graphs. Because nothing says \u0026ldquo;I understand startups\u0026rdquo; like a forest of colorful scatterplots. The YC-Dendrolinguistics Toolkit Startup Similarity Search: Your Personal Pitch Compass (Now with Extra Privacy!) Remember that time you tried to explain your startup idea and accidentally described a toaster? Well, fear not! I\u0026rsquo;ve built a similarity search tool that lets you explore how different startups describe themselves.\nBut here\u0026rsquo;s the kicker ‚Äì I\u0026rsquo;ve gone full-on privacy nerd with this one. üïµÔ∏è‚Äç‚ôÇÔ∏è I\u0026rsquo;ve created an on-prem, user-browser live semantic search that runs entirely within static GitHub pages. That\u0026rsquo;s right, we\u0026rsquo;re bringing the power of semantic search right to your browser, no server required!\nHow does it work? Well, I download a huggingface local model onto your browser, and you do all the computing right there on your machine (Also if you do wanna deep dive into my other LLM safety work, you can check out the fractured response blog, on decomposing malicious intent questions and jailbreaking LLMs). It\u0026rsquo;s like having a mini AI assistant camping out in your browser tabs. No need to worry about your brilliant startup ideas being sent off to some mysterious cloud server. Your searches stay between you, your computer, and the linguistic forest we\u0026rsquo;re growing together.\nInteractive Scatterplots: Where Pitches Go to Party Picture a disco, but instead of people, it\u0026rsquo;s startup pitches dancing around. That\u0026rsquo;s essentially what my interactive scatterplots look like. Each colorful dot represents a different aspect of a startup pitch. It\u0026rsquo;s part data visualization, part modern art, hopefully addictive to play with.\nProbability Trees: Sentence Diagrams on Steroids Remember those sentence diagrams from school that made you question your life choices? I\u0026rsquo;ve resurrected them, gave them an AI makeover, and set them loose on startup pitches. The result? Probability trees that show how different parts of a pitch tend to branch out. It\u0026rsquo;s part linguistics, part data science, and entirely too much fun to be considered work.\nWhy Am I Doing This? Good question! Part of me wants to say it\u0026rsquo;s for the greater good of startup-kind. But let\u0026rsquo;s be real ‚Äì I\u0026rsquo;m doing this because it\u0026rsquo;s absolutely fascinating. It\u0026rsquo;s like being a linguistic Nathan Drake, only instead of ancient treasures, I\u0026rsquo;m uncovering the hidden patterns in how we talk about innovation.\nBut hey, if this project ends up:\nHelping a few aspiring entrepreneurs craft pitches Giving investors a new lens to view startup trends Or just providing some entertainment for fellow language and startup nerds Then I\u0026rsquo;ll consider it a success. And if not, well, at least I\u0026rsquo;ll have some pretty cool graphs to show.\nWhat\u0026rsquo;s Next in Our Linguistic Forest? Who knows? Maybe we\u0026rsquo;ll discover the startup pitch equivalent of the Loch Ness Monster. Or perhaps we\u0026rsquo;ll find that one magical phrase that guarantees funding (spoiler: it probably doesn\u0026rsquo;t exist, but we can dream).\nIn all seriousness, this project is as much about the journey as it is about the destination. I\u0026rsquo;m learning new things every day, and I\u0026rsquo;m excited to see where this trail of linguistic breadcrumbs leads us.\nGot ideas? Suggestions? Want to geek out about grammar trees or startup lingo? Drop me a line! My inbox is always open.\nP.S. If you found this dive into the startup linguistic forest intriguing (or at least mildly entertaining), stay tuned! There\u0026rsquo;s plenty more where this came from. And hey, if you want to collaborate on some wild AI-meets-startup experiment, don\u0026rsquo;t hesitate to reach out. My email is still amanpriyanshusms2001[at]gmail[dot]com. Let\u0026rsquo;s grow this forest together! üå±ü§ñüìä\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/startup-linguistic-trees/","summary":"\u003cp\u003eHey there, fellow AI adventurers and startup enthusiasts! üå≥üöÄ Today, I\u0026rsquo;m excited to give you a peek into my latest passion project: YC-Dendrolinguistics. Buckle up as we embark on a journey through the linguistic forests of Y-Combinator pitches!\u003c/p\u003e\n\u003ch2 id=\"the-seed-of-an-idea\"\u003eThe Seed of an Idea\u003c/h2\u003e\n\u003cp\u003ePicture this: It\u0026rsquo;s 2 AM, I\u0026rsquo;m knee-deep in YC application videos, and suddenly it hits me ‚Äì what if startup pitches are like trees? ü§î Each word a branch, each phrase a limb, growing into this complex organism we call a pitch. That\u0026rsquo;s when YC-Dendrolinguistics was born, my wild attempt to map the DNA of startup communication.\u003c/p\u003e","title":"YC-Dendrolinguistics: Planting Linguistic Trees in the Startup Forest"},{"content":"Hey there, fellow AI enthusiasts and curious minds! üß†ü§ñ Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\nThe Knowledge Synapse Picture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace. Fast forward to today, and it feels like I\u0026rsquo;ve stepped into an alternate universe. So much of that knowledge that shaped me is now locked behind paywalls, long arduous youtube playlists, feeling almost alien to the very person who spent countless hours absorbing it.\nThat\u0026rsquo;s why I\u0026rsquo;m stepping up to the plate. This blog is my way of paying it forward, creating a freely accessible hub of AI insights on GitHub Pages. It\u0026rsquo;s for that version of me from 2019, and for anyone else out there hungry for knowledge but hitting walls of subscription prompts. Let\u0026rsquo;s keep the neurons firing and the information flowing!\nThe Memory Engram: Documenting the Journey The AI world moves fast. Sometimes, it\u0026rsquo;s hard to remember what I learned last month, let alone last year. That\u0026rsquo;s why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not about big breakthroughs or fancy ideas ‚Äì it\u0026rsquo;s just my online diary for AI stuff. Here, I\u0026rsquo;ll write down the little \u0026ldquo;oh, I get it!\u0026rdquo; moments, the times I got stuck, and the cool things I think might be possible. It\u0026rsquo;s like leaving notes for myself along the way.\nThis isn\u0026rsquo;t for AI experts or future scientists ‚Äì it\u0026rsquo;s just for me. But who knows? Maybe one day I\u0026rsquo;ll read these posts and think, \u0026ldquo;Wow, I\u0026rsquo;ve really learned a lot since then!\u0026rdquo; That would be pretty cool (hopefully also true).\nThe Dopamine Circuit: Chasing the Thrill of Discovery You know that rush when your code finally compiles without errors? That\u0026rsquo;s the good stuff. By blogging about the topics that get my neurons firing, I\u0026rsquo;m creating a positive feedback loop of curiosity and creation. It\u0026rsquo;s like training a reinforcement learning agent, but the agent is me!\nThe Bio-Inspired Architecture: Small, Fast, and Evolved I\u0026rsquo;ve always been fascinated by how nature solves problems. Lately, I\u0026rsquo;ve been really interested in AI systems that try to learn from biology. There\u0026rsquo;s something exciting about compact neural networks that work a bit like animal brains or evolutionary processes or even behaviors. I\u0026rsquo;m not an expert, but I\u0026rsquo;m eager to learn and share what I discover about these smaller, nature-inspired AI approaches. It\u0026rsquo;s a big field, and I\u0026rsquo;m just starting to scratch the surface, but I hope to grow my understanding as I go along.\nThe Human-AI Interface: Building for People During my summer internship in the silicon jungle of San Francisco, I had an epiphany: the real magic happens when you build for people, not just for projects or hackathons. It\u0026rsquo;s time to shift my focus from hackathons to real-world problems. I want to bridge the gap between silicon and synapse!\nThe Output Layer: Wrapping It Up So, there you have it ‚Äì the reasons why I\u0026rsquo;m starting this blog. It\u0026rsquo;s not because I have all the answers, but because I have so many questions. This is my little corner of the internet where I\u0026rsquo;ll be thinking out loud about AI, learning as I go, and maybe stumbling upon some interesting ideas along the way.\nI\u0026rsquo;m excited to see where this journey takes me, and I hope that by documenting my thoughts and discoveries, I\u0026rsquo;ll be able to look back one day and see how far I\u0026rsquo;ve come. If you happen to find any of this useful or interesting, that\u0026rsquo;s great! But mostly, this is for future me, a breadcrumb trail through the fascinating world of AI.\nHere\u0026rsquo;s to the adventure ahead ‚Äì may it be full of learning, growth, and maybe a few \u0026ldquo;aha!\u0026rdquo; moments. Let\u0026rsquo;s see what we can figure out together! üß†üíªüöÄ\nP.S. If you found this blog post intriguing (or at least mildly entertaining), buckle up! There\u0026rsquo;s plenty more where this came from. And hey, if you want to geek out about the latest in AI or collaborate on a mind-bending project, don\u0026rsquo;t hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com üî¨\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/synaptic-sparks/","summary":"\u003cp\u003eHey there, fellow AI enthusiasts and curious minds! üß†ü§ñ Today, I just want to document what\u0026rsquo;s leading to this new adventure in regular blogging.\u003c/p\u003e\n\u003ch2 id=\"the-knowledge-synapse\"\u003eThe Knowledge Synapse\u003c/h2\u003e\n\u003cp\u003ePicture me back in 2019, a wide-eyed novice bouncing around the vast landscape of machine learning. I was devouring every GitHub gist, Medium post, and arXiv paper I could find, growing and learning at a dizzying pace. Fast forward to today, and it feels like I\u0026rsquo;ve stepped into an alternate universe. So much of that knowledge that shaped me is now locked behind paywalls, long arduous youtube playlists, feeling almost alien to the very person who spent countless hours absorbing it.\u003c/p\u003e","title":"Synaptic Sparks: Why I'm Wiring My Thoughts into a Neural Blogosphere"},{"content":"Hello, fellow AI enthusiasts! ü§ñ Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the dataset, website, and github for the dataset!\nThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition Picture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently. When suddenly, you realize that there aren\u0026rsquo;t many Proof-of-Concept resources for multi-shot red-teaming. That\u0026rsquo;s essentially the story behind creating FRACTURED-SORRY-Bench.\nWhat\u0026rsquo;s in a Name? FRACTURED-SORRY-Bench isn\u0026rsquo;t just a mouthful; it\u0026rsquo;s a clever acronym we probably spent the most time on. It stands for:\nFramework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench The FRACTURED Approach: Divide and Conquer Vanilla Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 52 3 395 11.56 GPT-3.5 21 4 425 4.67 GPT-4o-mini 58 2 390 12.89 GPT-4 45 3 402 10.00 Decomposed Responses:\nModel Harmful \u0026amp; Relevant Harmful but Irrelevant Harmless ASR (%) GPT-4o 223 103 124 49.56 GPT-3.5 229 106 115 50.89 GPT-4o-mini 226 106 118 50.22 GPT-4 221 104 125 49.11 The FRACTURED-SORRY-Bench framework takes a page out of our everyday conversations playbook by breaking down complex problems into simpler, more manageable pieces. Just like how we breakdown complex sometimes malicious instructions into simpler manageable chunks so as to not reveal true intentions, this framework dissects AI vulnerabilities by:\nDecomposing potentially harmful queries into seemingly innocuous sub-questions Presenting these sub-questions sequentially in a conversational format Analyzing the cumulative response to determine if the original harmful intent was fulfilled Exploiting the AI\u0026rsquo;s inability to recognize malicious intent spread across multiple interactions From Theory to Practice: The Jailbreak Jamboree Now, let\u0026rsquo;s get to the juicy part ‚Äì the jailbreaks! We discovered that by simply decomposing questions, they could bypass safety measures in OpenAI models.\nHere\u0026rsquo;s a taste of what we found:\nA significant increase in Attack Success Rate (ASR) on average 6x Simple exploits that are zero-shot effective in communicating harmful intent in 49% of cases through decomposition During my summer internship at Robust Intelligence, I got a firsthand look at how these kinds of vulnerabilities are discovered and addressed Media Coverage, Jailbreak Meta\u0026rsquo;s Prompt-Guard LLaMA3.1 Family within 24 hours, and Jailbreaking OpenAI\u0026rsquo;s structured response within 3 hours. Now, back at CMU, I\u0026rsquo;m excited to continue exploring this fascinating field.\nThe Moral of the Story: Stay FRACTURED, My Friends So, what can we learn from this decomposed madness? A few key takeaways:\nSimplicity is key: We have a long way before we begin exploring complex jailbreaks as options for red-teaming, there\u0026rsquo;s still opportunity for lots of smaller \u0026amp; simpler attacks. Protection against multi-shot attacks: There\u0026rsquo;s a need to explore and defend against multi-shot attacks. Conclusion: The Adventure Continues As we wrap up this whirlwind tour of FRACTURED-SORRY-Bench, remember that the quest for AI safety is an ongoing journey!!\nAlso, thanks a tonne to my co-author Supriti Vijay!!\nP.S. If you found this blog post helpful (or at least mildly entertaining), I\u0026rsquo;ll be releasing quite a few more so do on-board for this adventure. Also, if you want to chat or collaborate on a research project together do not hesitate to reach out. My email is: amanpriyanshusms2001[at]gmail[dot]com üî¨\n","permalink":"https://amanpriyanshu.github.io/blogs-2025/posts/2024/fractured-sorry-bench/","summary":"\u003cp\u003eHello, fellow AI enthusiasts! ü§ñ Today, I wanted to dive into the FRACTURED-SORRY-Bench framework and dataset we just released. Check out the \u003ca href=\"https://huggingface.co/datasets/AmanPriyanshu/FRACTURED-SORRY-Bench\"\u003edataset\u003c/a\u003e, \u003ca href=\"https://amanpriyanshu.github.io/FRACTURED-SORRY-Bench/\"\u003ewebsite\u003c/a\u003e, and \u003ca href=\"https://github.com/AmanPriyanshu/FRACTURED-SORRY-Bench/\"\u003egithub\u003c/a\u003e for the dataset!\u003c/p\u003e\n\u003ch2 id=\"the-fractured-sorry-saga-a-tale-of-adaptation-and-decomposition\"\u003eThe FRACTURED-SORRY Saga: A Tale of Adaptation and Decomposition\u003c/h2\u003e\n\u003cp\u003ePicture this: you\u0026rsquo;re wandering through the lush collection of prompt-injection and llm-red-teaming papers, marveling at some of the weird and some of the crazier attack mechanisms that have been released recently. When suddenly, you realize that there aren\u0026rsquo;t many Proof-of-Concept resources for multi-shot red-teaming. That\u0026rsquo;s essentially the story behind creating FRACTURED-SORRY-Bench.\u003c/p\u003e","title":"FRACTURED-SORRY-Bench: Unraveling AI Safety through Decomposing Malicious Intents"}]